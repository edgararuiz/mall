{
  "hash": "2a4673556dcb5c24df2494e629379dc5",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: MallFrame\n---\n\n\n\n`MallFrame(self, df)`\n\nExtension to Polars that add ability to use\nan LLM to run batch predictions over a data frame\n\n## Methods\n\n| Name | Description |\n| --- | --- |\n| [classify](#mall.MallFrame.classify) | Classify text into specific categories. |\n| [sentiment](#mall.MallFrame.sentiment) | Use an LLM to run a sentiment analysis |\n| [summarize](#mall.MallFrame.summarize) | Summarise the text down to a specific number of words. |\n| [translate](#mall.MallFrame.translate) | Translate text into another language. |\n| [use](#mall.MallFrame.use) | Define the model, backend, and other options to use to  |\n\n### classify { #mall.MallFrame.classify }\n\n`MallFrame.classify(col, labels='', additional='', pred_name='classify')`\n\nClassify text into specific categories.\n\n#### Parameters\n\n| Name         | Type   | Description                                                                                                             | Default      |\n|--------------|--------|-------------------------------------------------------------------------------------------------------------------------|--------------|\n| `col`        |        | The name of the text field to process                                                                                   | _required_   |\n| `labels`     |        | A list or a DICT object that defines the categories to classify the text as. It will return one of the provided labels. | `''`         |\n| `pred_name`  |        | A character vector with the name of the new column where the prediction will be placed                                  | `'classify'` |\n| `additional` |        | Inserts this text into the prompt sent to the LLM                                                                       | `''`         |\n\n### sentiment { #mall.MallFrame.sentiment }\n\n`MallFrame.sentiment(col, options=['positive', 'negative', 'neutral'], additional='', pred_name='sentiment')`\n\nUse an LLM to run a sentiment analysis\n\n#### Parameters\n\n| Name         | Type   | Description                                                                            | Default                               |\n|--------------|--------|----------------------------------------------------------------------------------------|---------------------------------------|\n| `col`        |        | The name of the text field to process                                                  | _required_                            |\n| `options`    |        | A list of the sentiment options to use, or a named DICT object                         | `['positive', 'negative', 'neutral']` |\n| `pred_name`  |        | A character vector with the name of the new column where the prediction will be placed | `'sentiment'`                         |\n| `additional` |        | Inserts this text into the prompt sent to the LLM                                      | `''`                                  |\n\n#### Examples\n\n\n::: {#418566ee .cell execution_count=1}\n``` {.python .cell-code}\nimport mall\nimport polars as pl\ndata = mall.MallData\nreviews = data.reviews\nreviews.llm.use(options = dict(seed = 100), _cache = \"_readme_cache\")\nreviews.llm.sentiment(\"review\")\n```\n:::\n\n\n### summarize { #mall.MallFrame.summarize }\n\n`MallFrame.summarize(col, max_words=10, additional='', pred_name='summary')`\n\nSummarise the text down to a specific number of words.\n\n#### Parameters\n\n| Name         | Type   | Description                                                                            | Default     |\n|--------------|--------|----------------------------------------------------------------------------------------|-------------|\n| `col`        |        | The name of the text field to process                                                  | _required_  |\n| `max_words`  |        | Maximum number of words to use for the summary                                         | `10`        |\n| `pred_name`  |        | A character vector with the name of the new column where the prediction will be placed | `'summary'` |\n| `additional` |        | Inserts this text into the prompt sent to the LLM                                      | `''`        |\n\n### translate { #mall.MallFrame.translate }\n\n`MallFrame.translate(col, language='', additional='', pred_name='translation')`\n\nTranslate text into another language.\n\n#### Parameters\n\n| Name         | Type   | Description                                                                            | Default         |\n|--------------|--------|----------------------------------------------------------------------------------------|-----------------|\n| `col`        |        | The name of the text field to process                                                  | _required_      |\n| `language`   |        | The target language to translate to. For example 'French'.                             | `''`            |\n| `pred_name`  |        | A character vector with the name of the new column where the prediction will be placed | `'translation'` |\n| `additional` |        | Inserts this text into the prompt sent to the LLM                                      | `''`            |\n\n### use { #mall.MallFrame.use }\n\n`MallFrame.use(backend='', model='', _cache='_mall_cache', **kwargs)`\n\nDefine the model, backend, and other options to use to \ninteract with the LLM.\n\n#### Parameters\n\n| Name       | Type   | Description                                                                                                                                              | Default         |\n|------------|--------|----------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------|\n| `backend`  | str    | The name of the backend to use. At the beginning of the session it defaults to \"ollama\". If passing `\"\"`, it will remain unchanged                       | `''`            |\n| `model`    | str    | The name of the model tha the backend should use. At the beginning  of the session it defaults to \"llama3.2\". If passing `\"\"`, it will  remain unchanged | `''`            |\n| `_cache`   | str    | The path of where to save the cached results. Passing `\"\"` disables the cache                                                                            | `'_mall_cache'` |\n| `**kwargs` |        | Arguments to pass to the downstream Python call. In this case, the `chat` function in `ollama`                                                           | `{}`            |\n\n",
    "supporting": [
      "MallFrame_files"
    ],
    "filters": [],
    "includes": {}
  }
}