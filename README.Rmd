---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
library(dplyr)
```

# `mall`

<!-- badges: start -->
<!-- badges: end -->

Run multiple LLM predictions against a table. The predictions run row-wise
over a specified column. It works using a pre-determined one-shot prompt, along
with the current row's content. The prompt that is use will depend of the
type of analysis needed. Currently, the included prompts perform the following: 

- Sentiment analysis
- Summarize the text
- Extract one, or several, specific pieces information from the text


This package is inspired by the SQL AI functions now offered by vendors such as
[Databricks](https://docs.databricks.com/en/large-language-models/ai-functions.html) 
and Snowflake. For local data, `mall` uses Ollama to call an LLM. 

If you pass a table connected to **Databricks** via ODBC, `mall` will automatically
use Databricks' LLM instead of Ollama. It will call the corresponding SQL AI 
function. 

## Motivation

We want to help data scientists use LLMs in a new way. Typically, LLMs have been
used to ask coding questions (chat) or for code completion (Copilot). This 
interface provides an easy way to analyze text data, and without
having to spend time writing an NLP model. 

## Examples

We will start with a very small table with product reviews:

```{r}
library(dplyr)

reviews  <- tribble(
  ~ review,
    "This has been the best TV I've ever used. Great screen, and sound.", 
    "I regret buying this laptop. It is too slow and the keyboard is too noisy", 
    "Not sure how to feel about my new washing machine. Great color, but hard to figure"
  )
```

```{r, include=FALSE}
# Customizing print for tibble because the 'review' is too long, and doesn't
# allow new columns to be read

library(tibble)
library(pillar)

reviews <- new_tibble(reviews, class = "tbl_long")

ctl_new_pillar.tbl_long <- function(controller, x, width, ...) {
  out <- NextMethod()
  if(attr(out$data, "width") > 50) {
    attr(out$data, "width") <- 40
  }
  new_pillar(list(
    title = out$title,
    type = out$type, 
    data = out$data
  ))
}
```

The main functions in `mall` are verb-like functions that expect a `tbl` as 
their first argument. This allows us to use them in piped operations. 

### Sentiment

For the first example, we'll asses the sentiment of each review. In order to 
do this we will call `llm_sentiment()`:

```{r}
library(mall)

reviews |>
  llm_sentiment(review)
```

The function let's us modify the options to choose from: 

```{r}
reviews |>
  llm_sentiment(review, options = c("positive", "negative"))
```

As mentioned before, by being pipe friendly, the results from the LLM prediction
can be used in further transformations: 

```{r}
reviews |>
  llm_sentiment(review, options = c("positive", "negative")) |> 
  filter(.sentiment == "negative")
```


```{r}
reviews |> 
  llm_summarize(review, max_words = 5) 
```

```{r}
reviews |> 
  llm_summarize(review, max_words = 5, pred_name = "review_summary") 
```



```{r}
reviews |>
  llm_extract(review, "product")
```
