% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/llm-use.R
\name{llm_use}
\alias{llm_use}
\title{Specify the model to use}
\usage{
llm_use(
  backend = NULL,
  model = NULL,
  ...,
  .silent = FALSE,
  .cache = "_mall_cache",
  .force = FALSE
)
}
\arguments{
\item{backend}{The name of an supported back-end provider. Currently only
'ollama' is supported.}

\item{model}{The name of model supported by the back-end provider}

\item{...}{Additional arguments that this function will pass down to the
integrating function. In the case of Ollama, it will pass those arguments to
\code{ollamar::chat()}.}

\item{.silent}{Avoids console output}

\item{.cache}{The path to save model results, so that they can be re-used if
the same operation is ran again. Set to an empty character, or NULL to turn
off this feature. It defaults to '_mall_cache'.}

\item{.force}{Flag that tell the function to reset all of the settings in the
R session}
}
\value{
A \code{mall_defaults} object
}
\description{
Allows us to specify the back-end provider, model to use during the current
R session
}
